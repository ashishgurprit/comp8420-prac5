{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "61b82838",
      "metadata": {
        "id": "61b82838"
      },
      "source": [
        "# Week 5 Practical\n",
        "\n",
        "You have just thought up your latest brilliant idea -- an on-device spam SMS detector.\n",
        "\n",
        "Because it has to run on a mobile device, you can't use a modern LLM: you'll have to\n",
        "use a fine-tuned very small language model.\n",
        "\n",
        "Unfortunately, you don't have a lot of spam available right now to train on^. You\n",
        "have just a handful of SMS messages that you have labelled yourself, and some unlabelled\n",
        "SMS messages your friends have given you.\n",
        "\n",
        "^ Actually, it you were doing this in English, you would, because there are spam SMS\n",
        "corpora on https://archive.ics.uci.edu/dataset/228/sms+spam+collection. But if you were doing this in a less well-resourced language, you would have to do something like this\n",
        "prac.\n",
        "\n",
        "Note that these techniques don't always make much of an improvement. Sometimes they even make things worse.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619c568b",
      "metadata": {
        "id": "619c568b"
      },
      "source": [
        "- Your initial spam dataset is in `spam.csv`\n",
        "- Your initial ham dataset is in `ham.csv`\n",
        "- Your unlabelled data is in `unlabelled.csv`\n",
        "\n",
        "Do your usual EDA (exploratory data analysis), have a look at a few samples, review the shape of these datasets, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d57f92",
      "metadata": {
        "id": "c9d57f92"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "\n",
        "\n",
        "\n",
        "initial_spam.shape, initial_ham.shape, unlabelled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95b866d3",
      "metadata": {
        "id": "95b866d3"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32dfbadb",
      "metadata": {
        "id": "32dfbadb"
      },
      "source": [
        "We'll need to make a training and test dataset out of this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5da72a2",
      "metadata": {
        "id": "b5da72a2"
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection\n",
        "pandas.concat([initial_spam, initial_ham])\n",
        "\n",
        "\n",
        "train_df, test_df ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b990f89a",
      "metadata": {
        "id": "b990f89a"
      },
      "source": [
        "How many positive examples of spam and ham do we have in our training and test datasets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1ddef3",
      "metadata": {
        "id": "ab1ddef3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f3236146",
      "metadata": {
        "id": "f3236146"
      },
      "source": [
        "Below is a function that you can call that will fine-tune a GPT2 model on the\n",
        "training data, and report its accuracy on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c54c8c",
      "metadata": {
        "id": "d0c54c8c"
      },
      "outputs": [],
      "source": [
        "from transformers import MobileBertTokenizer, MobileBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, DistributedSampler, random_split\n",
        "import torch\n",
        "import functools\n",
        "from sklearn.metrics import accuracy_score, log_loss, recall_score, precision_score\n",
        "import numpy\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = numpy.argmax(p.predictions, axis=1)\n",
        "    corrects = numpy.argmax(p.label_ids, axis=1)\n",
        "    return {\"accuracy\": accuracy_score(corrects, preds),\n",
        "           \"log_loss\": log_loss(corrects, p.predictions),\n",
        "            \"recall\": recall_score(corrects, preds),\n",
        "            \"precision\": precision_score(corrects, preds),\n",
        "            \"predictions\": preds,\n",
        "            \"correct_answers\": corrects,\n",
        "            \"prediction logits\": p.predictions\n",
        "           }\n",
        "\n",
        "\n",
        "class TwoColumnDFDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.data.text.iloc[index])\n",
        "        text = \" \".join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=50, # An SMS won't be much longer than this\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        ids = inputs['input_ids'][0]\n",
        "        mask = inputs['attention_mask'][0]\n",
        "        labels = [0,1] if self.data.spam.iloc[index] == 'spam' else [1,0]\n",
        "        return {\n",
        "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'labels': torch.tensor(labels, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "def train_and_evaluate_model(train_df, test_df):\n",
        "    model = MobileBertForSequenceClassification.from_pretrained('google/mobilebert-uncased')\n",
        "    training_set = TwoColumnDFDataset(train_df)\n",
        "    testing_set = TwoColumnDFDataset(test_df)\n",
        "    print(f\"The training data has {train_df.shape[0]} rows\")\n",
        "    print(f\"The test data has {test_df.shape[0]} rows\")\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=50,\n",
        "        per_device_train_batch_size=len(training_set),\n",
        "        per_device_eval_batch_size=len(testing_set),\n",
        "        warmup_steps=10,\n",
        "        weight_decay=0.1,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        #use_mps_device=False,\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=training_set,\n",
        "        eval_dataset=testing_set,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    trainer.train()\n",
        "    return {\n",
        "        'model': model,\n",
        "        'evaluation': trainer.evaluate()\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3db13251",
      "metadata": {
        "id": "3db13251"
      },
      "source": [
        "Let's do a baseline run where we train the model on the data we have, and see\n",
        "how accurate it is.\n",
        "\n",
        "You might need to scroll the cell down to see the part where it shows the evaluation.\n",
        "Make a note of the eval_loss, eval_accuracy, eval_recall and eval_precision. One\n",
        "small problem with this prac is that it is often so easy to separate SMS spam from ham\n",
        "that even 10 samples is sometimes enough!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b60665",
      "metadata": {
        "id": "37b60665"
      },
      "outputs": [],
      "source": [
        "%%time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "076c8f77",
      "metadata": {
        "id": "076c8f77"
      },
      "source": [
        "# Where to begin\n",
        "\n",
        "Sometimes, if there's not enough labelled training data, the best thing to do is to\n",
        "label some data yourself. You get a lot of insight from this too.\n",
        "\n",
        "Randomly pick one of the unlabelled SMS texts, and decide if it is spam or ham.\n",
        "\n",
        "Create a new `training2_df` which consists of `train_df` and your new manually-labelled\n",
        "point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8179a20a",
      "metadata": {
        "id": "8179a20a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2419d7",
      "metadata": {
        "id": "eb2419d7"
      },
      "outputs": [],
      "source": [
        "manually_labelled ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb808ed1",
      "metadata": {
        "id": "cb808ed1"
      },
      "source": [
        "Re-run the training and evaluation function on this new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf54668",
      "metadata": {
        "id": "6bf54668"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fc098d58",
      "metadata": {
        "id": "fc098d58"
      },
      "source": [
        "## \"Blind\" Data Augmentation\n",
        "\n",
        "Grab your favourite LLM, and get it to make up some 20 fake SMS messages.\n",
        "You don't need to do anything fancy with an API here. It's OK to copy-and-paste\n",
        "it from the LLM into here as JSON or CSV that you then turn into a dataframe.\n",
        "\n",
        "Examples are as follow:\n",
        "spam: [\n",
        "  {\n",
        "    \"sender\": \"555-555-5555\",\n",
        "    \"message\": \"Congratulations! You are pre-approved for a loan of $5000. Reply STOP to opt-out.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"888-888-8888\",\n",
        "    \"message\": \"Win a free vacation! Click link to claim: bit.ly/freevacation (limited time only)\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"666-666-6666\",\n",
        "    \"message\": \"Urgent action required: Your account will be suspended. Call now to resolve: 888-888-8888\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"777-777-7777\",\n",
        "    \"message\": \"You've won! $1000 gift card to your favorite store. Click link to claim: bit.ly/giftcard1000\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"555-555-5555\",\n",
        "    \"message\": \"Last chance to save! 75% off all items. Shop now: bit.ly/huge sale\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"888-888-8888\",\n",
        "    \"message\": \"Don't miss out! Exclusive offer for you: 50% off your next purchase. Use code SMS50\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"666-666-6666\",\n",
        "    \"message\": \"Warning: Your device may be infected. Click link to scan: bit.ly/devicescan\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"777-777-7777\",\n",
        "    \"message\": \"Breaking news: Major security breach. Click link to learn more: bit.ly/securitybreach\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"555-555-5555\",\n",
        "    \"message\": \"Important update: Your order has shipped. Track now: bit.ly/track12345\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"888-888-8888\",\n",
        "    \"message\": \"Reminder: Your appointment is tomorrow at 10am. Confirm by replying YES\"\n",
        "  }\n",
        "]\n",
        "\n",
        "ham: [\n",
        "  {\n",
        "    \"sender\": \"555-555-5555\",\n",
        "    \"message\": \"Hey there, just wanted to check in and see how everything is going. Let me know if you need anything.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"888-888-8888\",\n",
        "    \"message\": \"Hi, I'm following up on the project we discussed earlier. Do you have an update for me?\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"666-666-6666\",\n",
        "    \"message\": \"Hello, I wanted to confirm our meeting tomorrow at 2pm. Looking forward to it!\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"777-777-7777\",\n",
        "    \"message\": \"Hey, I just wanted to let you know that the report you requested is attached. Let me know if you have any questions.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"555-555-5555\",\n",
        "    \"message\": \"Hi, I hope you're doing well. I just wanted to follow up on the email I sent earlier this week. Let me know if you've had a chance to review it.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"888-888-8888\",\n",
        "    \"message\": \"Hello, I wanted to let you know that the event has been rescheduled for next Friday at 3pm. I hope you can still make it.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"666-666-6666\",\n",
        "    \"message\": \"Hey, I just wanted to remind you about the deadline for the project. Let me know if you need any help or resources.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"777-777-7777\",\n",
        "    \"message\": \"Hi, I hope you had a great weekend. I just wanted to check in and see if you have any updates for me.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"555-555-5555\",\n",
        "    \"message\": \"Hello, I wanted to let you know that the files you requested have been uploaded to the shared drive. Let me know if you have any issues accessing them.\"\n",
        "  },\n",
        "  {\n",
        "    \"sender\": \"888-888-8888\",\n",
        "    \"message\": \"Hey, I just wanted to confirm that we're still on for our call at 11am. See you then!\"\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a47d0613",
      "metadata": {
        "id": "a47d0613"
      },
      "outputs": [],
      "source": [
        "mixtral_output_spam = pandas.DataFrame.from_records()\n",
        "\n",
        "mixtral_output_ham = pandas.DataFrame.from_records()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1defe11c",
      "metadata": {
        "id": "1defe11c"
      },
      "source": [
        "Concatenate your fake data and the training data into a new dataframe (call it\n",
        "`training3_df`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd26802",
      "metadata": {
        "id": "afd26802"
      },
      "outputs": [],
      "source": [
        "training3_df ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241e483c",
      "metadata": {
        "id": "241e483c"
      },
      "source": [
        "Did that make any difference to accuracy, or the loss? (It might actually\n",
        "make it worse if the synthetic data isn't representative of the test data.\n",
        "But we would expect it will generalise better to other spam data in the future.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8df52be0",
      "metadata": {
        "id": "8df52be0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "19fdeeee",
      "metadata": {
        "id": "19fdeeee"
      },
      "source": [
        "-----\n",
        "\n",
        "## Fast zero-shot learning\n",
        "\n",
        "There are several ways that we can add more data. We have lots of\n",
        "unlabelled data. Is there anything we can do with that?\n",
        "\n",
        "One way is to use a large LLM to decide whether something is spam or not.\n",
        "\n",
        "We can speed this up: we don't need a lot of text generated. Let's just\n",
        "look at the first token.\n",
        "\n",
        "Here's some code that gets the probability distribution that GPT-2 gives\n",
        "for the next token in a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4befd562",
      "metadata": {
        "id": "4befd562"
      },
      "source": [
        "First we'll do an example. I keep getting Harry Potter and Star Wars mixed\n",
        "up. Is Harry Potter the one with the wizards, or the one with the jedi?\n",
        "\n",
        "If it's the one about wizards, then there'll be a higher probability\n",
        "that the next word in \"Harry Potter is a famous novel about...\" will be\n",
        "wizards than jedi.\n",
        "\n",
        "Let's check it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d26d982d",
      "metadata": {
        "id": "d26d982d"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "def probability_distribution_of_next_token(input_text, return_top_k=10):\n",
        "    # Step 1 & 2: Load the tokenizer and model\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Step 3: Preprocess input text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    # Step 4: Predict the next token's probability distribution\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        outputs = model(input_ids)\n",
        "        predictions = outputs.logits\n",
        "\n",
        "    # Step 5: Convert logits to probabilities\n",
        "    probabilities = torch.softmax(predictions[:, -1, :], dim=-1)\n",
        "\n",
        "    top_probs, top_ids = probabilities.topk(return_top_k)\n",
        "    answers = []\n",
        "    for prob, token_id in zip(top_probs[0], top_ids[0]):\n",
        "        token = tokenizer.decode(token_id, clean_up_tokenization_spaces=True)\n",
        "        answers.append({\"token\": token, \"probability\": prob.item()})\n",
        "    return pandas.DataFrame.from_records(answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3335f5b",
      "metadata": {
        "id": "b3335f5b"
      },
      "outputs": [],
      "source": [
        "probability_distribution_of_next_token(\"Harry Potter is a famous novel about\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "440f415e",
      "metadata": {
        "id": "440f415e"
      },
      "source": [
        "It's about wizards. I don't need to go any further.\n",
        "\n",
        "So how would we apply this to spam detection? We could take a message and wrap it in\n",
        "\"Spam or ham? The message `...` is a \" and see what comes next. Note that the tokenizer breaks \"spam\" into \"sp\" + \"am\", so we're looking for \"sp\" or \"ham\".\n",
        "\n",
        "Pick a random spam message, and see what comes up first. You'll need to get the top\n",
        "10,000 token distributions typically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b631b076",
      "metadata": {
        "id": "b631b076"
      },
      "outputs": [],
      "source": [
        "p = probability_distribution_of_next_token()\n",
        "p[p.token.isin(['sp', 'ham'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ebf814f",
      "metadata": {
        "id": "1ebf814f"
      },
      "source": [
        "Now do a random ham message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4b8bc7",
      "metadata": {
        "id": "7d4b8bc7"
      },
      "outputs": [],
      "source": [
        "p = probability_distribution_of_next_token()\n",
        "p[p.token.isin(['sp', 'ham'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f45234f",
      "metadata": {
        "id": "9f45234f"
      },
      "source": [
        "Hopefully that's looking OK-ish and right most of the\n",
        "time. So now we write a fast ham/spam tester. It would\n",
        "require too much memory for a phone (probably) but at least we can label some\n",
        "of our unlabelled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a96487",
      "metadata": {
        "id": "64a96487"
      },
      "outputs": [],
      "source": [
        "def llm_based_inference(text):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3308a5a8",
      "metadata": {
        "id": "3308a5a8"
      },
      "source": [
        "How good is it? Is it more accurate than our existing models? Test it out on our\n",
        "known data and get some numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6907ca23",
      "metadata": {
        "id": "6907ca23"
      },
      "outputs": [],
      "source": [
        "initial_ham.text.map(llm_based_inference).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3f8f43",
      "metadata": {
        "id": "be3f8f43"
      },
      "outputs": [],
      "source": [
        "initial_spam.text.map(llm_based_inference).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d1030d",
      "metadata": {
        "id": "12d1030d"
      },
      "source": [
        "Let's take 20 of the unlabelled messages and label them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5976edeb",
      "metadata": {
        "id": "5976edeb"
      },
      "outputs": [],
      "source": [
        "llm_labelled = unlabelled.sample(20)\n",
        "llm_labelled['spam'] ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a7637f",
      "metadata": {
        "id": "90a7637f"
      },
      "source": [
        "Add them to the dataset. Call it `training4_df`, and check out how our accuracy is now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3dcf84",
      "metadata": {
        "id": "fb3dcf84"
      },
      "outputs": [],
      "source": [
        "training4_df ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f26a18b",
      "metadata": {
        "id": "1f26a18b"
      },
      "source": [
        "## Augmentation via translation\n",
        "\n",
        "Let's take our original training spam and ham messages, and translate them into French\n",
        "and then back again. Since we don't much care about the details of the translation\n",
        "model (we aren't going to fine tune it) we can just use Hugging Face's `pipeline`.\n",
        "Search the HuggingFace hub for some models that do English to French and French to\n",
        "English translation.\n",
        "\n",
        "If we translate the test spam and ham messages, we'll probably leak test information\n",
        "into the training data set.\n",
        "\n",
        "Compare the results and see whether it has generated something reasonable and new."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "655e135b",
      "metadata": {
        "id": "655e135b"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "en_fr_translator = pipeline(\"translation_en_to_fr\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd3ad63",
      "metadata": {
        "id": "ccd3ad63"
      },
      "outputs": [],
      "source": [
        "%%time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe44a25",
      "metadata": {
        "id": "0fe44a25"
      },
      "source": [
        "Results for English <-> Chinese are often remarkably terrible because\n",
        "lots of information is assumed in Chinese that is explicit in English\n",
        "and vice versa.\n",
        "\n",
        "Just do a few until you see one that's hilariously bad!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc81b91",
      "metadata": {
        "id": "4bc81b91"
      },
      "outputs": [],
      "source": [
        "en_zh_translator = pipeline(\"translation_en_to_zh\", model=\"Helsinki-NLP/opus-mt-en-zh\")\n",
        "zh_en_translator = pipeline(\"translation_zh_to_en\", model=\"Helsinki-NLP/opus-mt-zh-en\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b747ff21",
      "metadata": {
        "id": "b747ff21"
      },
      "source": [
        "Spam ends up particularly mangled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ac63a8c",
      "metadata": {
        "id": "9ac63a8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6729bd98",
      "metadata": {
        "id": "6729bd98"
      },
      "source": [
        "Add your new English <-> French spam and ham content in, and call it `training5_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "963538e7",
      "metadata": {
        "id": "963538e7"
      },
      "outputs": [],
      "source": [
        "translation_augmentation =\n",
        "\n",
        "training5_df ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea43e5cf",
      "metadata": {
        "id": "ea43e5cf"
      },
      "source": [
        "Have we improved the accuracy of our SMS model yet?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7231f1",
      "metadata": {
        "scrolled": true,
        "id": "6f7231f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "eaf2f876",
      "metadata": {
        "id": "eaf2f876"
      },
      "source": [
        "# Insert/delete/change augmentation\n",
        "\n",
        "We will use the nlpaug library ( https://github.com/makcedward/nlpaug ) which you install\n",
        "with `pip install nlpaug` or `conda install nlpaug`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406525df",
      "metadata": {
        "id": "406525df"
      },
      "outputs": [],
      "source": [
        "!pip install nlpaug"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da7ab46c",
      "metadata": {
        "id": "da7ab46c"
      },
      "source": [
        "Pick two of the word augmentation techniques from https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb\n",
        "and apply it to your `train_df` examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445b6e74",
      "metadata": {
        "id": "445b6e74"
      },
      "outputs": [],
      "source": [
        "import nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4920046f",
      "metadata": {
        "id": "4920046f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba2fd5f3",
      "metadata": {
        "id": "ba2fd5f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c404fee3",
      "metadata": {
        "id": "c404fee3"
      },
      "source": [
        "Make `training6_df` from your further augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e39ecb2",
      "metadata": {
        "id": "3e39ecb2"
      },
      "outputs": [],
      "source": [
        "training6_df ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9cf57d5",
      "metadata": {
        "id": "a9cf57d5"
      },
      "source": [
        "How is our accuracy and loss now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "780652cf",
      "metadata": {
        "id": "780652cf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a97315e8",
      "metadata": {
        "id": "a97315e8"
      },
      "source": [
        "Notice how much data we have now. Not bad, given we started with only 10 samples!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36c6b9a8",
      "metadata": {
        "id": "36c6b9a8"
      },
      "source": [
        "# What else you would normally try\n",
        "\n",
        "- Unsupervised data augmentation and Uncertainty-aware self-training are helpful,\n",
        "  if computationally heavy techniques.\n",
        "  \n",
        "- Label spreading algorithms can work if there is a lot of unlabelled data\n",
        "\n",
        "- Unsupervised methods on the unlabelled data to see if there are any obvious clusters\n",
        "\n",
        "- Explainable techniques: of the things that are distinct between the spam and ham\n",
        "  SMS messages, is there anything that might be usefully indicative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "853b4522",
      "metadata": {
        "id": "853b4522"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}